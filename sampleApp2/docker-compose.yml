# version: '3.8'

services:
  sampleapp2:
    build: . # Build context is current directory (sampleApp2/)
    container_name: sampleapp2-chatbot
    ports:
      - "5001:5001" # Host_port:Container_port for sampleapp2 (using 5001 as per your example)
    environment:
      # These variables are CRITICAL for sampleApp2 to communicate with Keystore
      # and the Generative AI API. They will be loaded from sampleApp2/.env
      - KEYSTORE_API_URL=${KEYSTORE_API_URL} # e.g., http://host.docker.internal:5000 or your Keystore's public IP
      - KEYSTORE_JWT_TOKEN=${KEYSTORE_JWT_TOKEN} # JWT for this app to access Keystore
      - GENERATIVE_AI_KEY_NAME=${GENERATIVE_AI_KEY_NAME} # Name of the key in Keystore
      - GENERATIVE_AI_MODEL=${GENERATIVE_AI_MODEL:-gemini-2.0-flash} # Default LLM model, can be overridden
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/"] # Check if index.html is served
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
